{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978958f8",
   "metadata": {
    "id": "978958f8"
   },
   "source": [
    "# Malware Classification with Graph Embeddings\n",
    "\n",
    "This notebook builds an end-to-end workflow to detect malware from function-call graphs. We rely on the MalNet Tiny dataset distributed via PyTorch Geometric, transform the graphs into vector representations, explore their structure, and finally train both classical ML and GNN models for classification. The dataset is pulled automatically from the [PyTorch Geometric documentation](https://pytorch-geometric.readthedocs.io/en/2.4.0/generated/torch_geometric.datasets.MalNetTiny.html) so no manual downloads are required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2bb45-3a04-4d68-9d6b-0a1e5a180c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed. Then restart the jupyter kernel\n",
    "# !uv pip install --no-cache-dir --force-reinstall joblib==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IaIrgl-tu9St",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IaIrgl-tu9St",
    "outputId": "9e009821-1abc-4833-ac8e-9e93d9becdc3"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from karateclub import Graph2Vec\n",
    "from umap.umap_ import UMAP\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "from pycaret.classification import (\n",
    "    setup, compare_models, finalize_model,\n",
    "    tune_model, evaluate_model, save_model, load_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5450a3",
   "metadata": {
    "id": "0f5450a3"
   },
   "source": [
    "## 1. Load MalNet Tiny Graphs\n",
    "Use the `MalNetTiny` dataset helper to download the graphs automatically, and keep a balanced subset of 200 graphs per class for faster experimentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d61ea2-5b66-402d-8fa6-67e7766050fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_GRAPHS = # À compléter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb442f-803d-428c-9ee7-06de8ad44734",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "CLASSES = ['addisplay', 'adware', 'benign', 'downloader', 'trojan']\n",
    "MAX_GRAPHS_BY_CLASSE = # À compléter\n",
    "\n",
    "targets = []\n",
    "graphs = []\n",
    "\n",
    "for classe in CLASSES:\n",
    "    files = Path(PATH_GRAPHS + '/' + classe).glob('*.edgelist')\n",
    "    for i, file in enumerate(files):\n",
    "        if i >= MAX_GRAPHS_BY_CLASSE:\n",
    "            break\n",
    "        targets.append(classe)\n",
    "        G = nx.read_edgelist(file)\n",
    "        G = nx.convert_node_labels_to_integers(G, label_attribute='old_label')\n",
    "        graphs.append(G)\n",
    "\n",
    "f\"{len(graphs)} graphes chargés ({dict(Counter(targets))})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda7dc9c",
   "metadata": {
    "id": "fda7dc9c"
   },
   "source": [
    "## 2. Graph Embedding\n",
    "Learn Graph2Vec representations that turn each graph into a dense vector suitable for downstream visualization and classification tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369dc814",
   "metadata": {
    "id": "369dc814"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "N_DIMENSIONS = # À compléter\n",
    "\n",
    "graph2vec = # À compléter\n",
    "# À compléter\n",
    "embeddings = # À compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b2f68",
   "metadata": {
    "id": "db6b2f68"
   },
   "source": [
    "**Plot the embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hl9z4JL9lh3W",
   "metadata": {
    "id": "hl9z4JL9lh3W"
   },
   "source": [
    "The interactive scatterplot helps verify whether Graph2Vec separates the malware families.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e178619",
   "metadata": {
    "id": "9e178619"
   },
   "outputs": [],
   "source": [
    "fig_2d = px.scatter(\n",
    "    # À compléter\n",
    ")\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952eeb1",
   "metadata": {
    "id": "2952eeb1"
   },
   "source": [
    "## 3. Dimensionality Reduction\n",
    "Use UMAP to reduce the high-dimensional embeddings to 2D and 3D views that make cluster structures easier to inspect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685ee5c8",
   "metadata": {
    "id": "685ee5c8"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "N_DIMENSIONS = # À compléter\n",
    "\n",
    "graph2vec = # À compléter\n",
    "# À compléter\n",
    "embeddings = # À compléter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339dc33e",
   "metadata": {
    "id": "339dc33e"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(embeddings)\n",
    "df['target'] = targets\n",
    "df.to_csv('../../data/malware_emb.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e992e7a",
   "metadata": {
    "id": "5e992e7a"
   },
   "source": [
    "**Project embeddings down to 2 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30980523",
   "metadata": {
    "id": "30980523"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "proj_2d = # À compléter\n",
    "proj_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dae71c7",
   "metadata": {
    "id": "5dae71c7"
   },
   "source": [
    "**Plot the 2D embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2gTfpKI1XJ",
   "metadata": {
    "id": "cb2gTfpKI1XJ"
   },
   "outputs": [],
   "source": [
    "fig_2d = # À compléter\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7899b",
   "metadata": {
    "id": "b3b7899b"
   },
   "source": [
    "**Project embeddings down to 3 dimensions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c21171",
   "metadata": {
    "id": "e0c21171"
   },
   "outputs": [],
   "source": [
    "proj_3d = # À compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b800e87",
   "metadata": {
    "id": "4b800e87"
   },
   "source": [
    "**Plot the 3D embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dc66f",
   "metadata": {
    "id": "135dc66f"
   },
   "outputs": [],
   "source": [
    "fig_3d = # À compléter\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd92bf-7ea2-40f1-9713-9b94f8159b71",
   "metadata": {},
   "source": [
    "#### Versus bad initial approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6409e87-eea2-4b79-9398-0f8dea34ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "N_DIMENSIONS = 3\n",
    "\n",
    "graph2vec = Graph2Vec(dimensions=N_DIMENSIONS)\n",
    "graph2vec.fit(graphs)\n",
    "embeddings = graph2vec.get_embedding()\n",
    "print(embeddings.shape)\n",
    "\n",
    "fig_3d = px.scatter_3d(\n",
    "    embeddings, x=0, y=1, z=2,\n",
    "    color=targets,\n",
    "    height=700\n",
    ")\n",
    "fig_3d.update_traces(marker_size=5)\n",
    "fig_3d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55510dde",
   "metadata": {
    "id": "55510dde"
   },
   "source": [
    "## 4. Classical Classification\n",
    "Each graph is annotated with a malware family (or the benign label), so we can train a supervised classifier that predicts one of the five categories automatically. We rely on PyCaret to quickly compare algorithms, tune the best one, and persist the winning model for later inference.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7f35e",
   "metadata": {
    "id": "80d7f35e"
   },
   "source": [
    "**Load the saved embeddings**\n",
    "\n",
    "Read the CSV file that stores the Graph2Vec representations alongside their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47583789",
   "metadata": {
    "id": "47583789"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/malware_emb.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2e2c4",
   "metadata": {
    "id": "27f2e2c4"
   },
   "source": [
    "**Initialize PyCaret**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8536fe",
   "metadata": {
    "id": "ca8536fe"
   },
   "outputs": [],
   "source": [
    "setup(# À compléter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c576fac",
   "metadata": {
    "id": "2c576fac"
   },
   "source": [
    "**Compare models**\n",
    "PyCaret benchmarks a wide range of classifiers so we can pick the one that offers the best accuracy for the selected embedding dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be1a95",
   "metadata": {
    "id": "17be1a95"
   },
   "outputs": [],
   "source": [
    "best_model = compare_models(exclude=['lightgbm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2d5be",
   "metadata": {
    "id": "dbe2d5be"
   },
   "source": [
    "**Tune the best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb658b",
   "metadata": {
    "id": "39eb658b"
   },
   "outputs": [],
   "source": [
    "best_model_tuned = tune_model(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5ee6ae",
   "metadata": {
    "id": "fb5ee6ae"
   },
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a2a48",
   "metadata": {
    "id": "df1a2a48"
   },
   "outputs": [],
   "source": [
    "evaluate_model(best_model)\n",
    "# addisplay: 0, adware: 1, benign: 2, downloader: 3, trojan: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9c1787",
   "metadata": {
    "id": "6e9c1787"
   },
   "source": [
    "**Save final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a1e336",
   "metadata": {
    "id": "a4a1e336"
   },
   "outputs": [],
   "source": [
    "final_model = finalize_model(best_model)\n",
    "save_model(final_model, 'ml_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81052e1e",
   "metadata": {
    "id": "81052e1e"
   },
   "outputs": [],
   "source": [
    "best_model = load_model('ml_model')\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68a0e9",
   "metadata": {},
   "source": [
    "### Autogluon VS PyCaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install autogluon\n",
    "!uv sync --extra autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fed2c-43a6-4449-9bc0-2a49b7293303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor, TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58c9ea6",
   "metadata": {},
   "source": [
    "Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52263b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, _, _ = train_test_split(df, targets, test_size=0.33, random_state=42)\n",
    "X_train.to_csv('train.csv', index=None)\n",
    "X_test.to_csv('test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3007045",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ea835d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TabularPredictor(label=\"target\").fit(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebeaca",
   "metadata": {},
   "source": [
    "Prediction on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c22c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(f'test.csv')\n",
    "\n",
    "y_pred = predictor.predict(test_data.drop(columns=['target']))\n",
    "y_pred[:10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1888d5",
   "metadata": {},
   "source": [
    "Evaluation of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b3d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8435dd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i68ofqznPJ3o",
   "metadata": {
    "id": "i68ofqznPJ3o"
   },
   "source": [
    "## 5. GNN-Based Classification\n",
    "Explore an end-to-end neural approach by training a Graph Convolutional Network (GCN) on the raw graphs instead of relying on precomputed embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c4fe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install torch and torch_geometric\n",
    "!uv sync --extra deep-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c042304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Dropout\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import BatchNorm, GCNConv, global_mean_pool\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "\n",
    "# hardware selection\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.version.cuda)\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.cuda.get_device_capability(0))\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(torch.__version__)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JdOejP9kPjSZ",
   "metadata": {
    "id": "JdOejP9kPjSZ"
   },
   "source": [
    "**Convert NetworkX graphs into PyG Data objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fW71glC0t6Rz",
   "metadata": {
    "id": "fW71glC0t6Rz"
   },
   "outputs": [],
   "source": [
    "# Convert NetworkX graphs into PyG Data objects, adding placeholder node features and labels.\n",
    "def convert_to_pyg(graphs, targets):\n",
    "    data_list = []\n",
    "    for i, graph in enumerate(graphs):\n",
    "        for node in graph.nodes():\n",
    "            graph.nodes[node]['x'] = [1.0]  # Constant node feature placeholder\n",
    "\n",
    "        data = from_networkx(graph)\n",
    "        data.y = torch.tensor([targets[i]], dtype=torch.long)\n",
    "        data_list.append(data)\n",
    "    return data_list\n",
    "\n",
    "class_mapping = {'addisplay': 0, 'adware': 1, 'benign': 2, 'downloader': 3, 'trojan': 4}\n",
    "encoded_targets = [class_mapping[label] for label in targets]\n",
    "\n",
    "data_list = convert_to_pyg(graphs, encoded_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qglUVAZUPa4J",
   "metadata": {
    "id": "qglUVAZUPa4J"
   },
   "source": [
    "**Create train/test splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z_2qLd2XulW_",
   "metadata": {
    "id": "Z_2qLd2XulW_"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into train and test partitions\n",
    "train_data, test_data = train_test_split(\n",
    "    data_list,\n",
    "    test_size=int(len(data_list) * 0.3),\n",
    "    stratify=encoded_targets,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Build PyG dataloaders\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ShA__SbTP7Sz",
   "metadata": {
    "id": "ShA__SbTP7Sz"
   },
   "source": [
    "**Define the GNN architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CT5SVZ4L7LrE",
   "metadata": {
    "id": "CT5SVZ4L7LrE"
   },
   "outputs": [],
   "source": [
    "# Deeper GNN classifier with normalization and dropout regularization\n",
    "class ImprovedGNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.norms = torch.nn.ModuleList()\n",
    "\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        self.norms.append(BatchNorm(hidden_channels))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "            self.norms.append(BatchNorm(hidden_channels))\n",
    "\n",
    "        self.dropout = Dropout(dropout)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        for conv, norm in zip(self.convs, self.norms):\n",
    "            x = conv(x, edge_index)\n",
    "            x = norm(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469665e6",
   "metadata": {},
   "source": [
    "Load or create a new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e18e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_previous_model = False\n",
    "\n",
    "if load_previous_model:\n",
    "    model = ImprovedGNNClassifier(\n",
    "        in_channels=checkpoint[\"in_channels\"],\n",
    "        hidden_channels=checkpoint[\"hidden_channels\"],\n",
    "        out_channels=checkpoint[\"out_channels\"],\n",
    "        num_layers=checkpoint[\"num_layers\"],\n",
    "        dropout=checkpoint[\"dropout\"],\n",
    "    ).to(device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.005,          # même LR qu’à l’entraînement initial\n",
    "        weight_decay=1e-4\n",
    "    )\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "else:\n",
    "    in_channels = 1\n",
    "    hidden_channels = 256  # Increased hidden size for better capacity\n",
    "    out_channels = len(class_mapping)\n",
    "    num_layers = 8  # Stack more GCN layers\n",
    "    dropout = 0.5\n",
    "\n",
    "    model = ImprovedGNNClassifier(in_channels, hidden_channels, out_channels, num_layers, dropout)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    model = model.to(device)\n",
    "    start_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84cc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / max(1, len(train_loader))\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    preds, labels = [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch)\n",
    "        predictions = out.argmax(dim=1)\n",
    "        correct += (predictions == batch.y).sum().item()\n",
    "        preds.extend(predictions.cpu().tolist())\n",
    "        labels.extend(batch.y.cpu().tolist())\n",
    "    accuracy = correct / len(loader.dataset)\n",
    "    return accuracy, preds, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Amy-HAmbhd1T",
   "metadata": {
    "id": "Amy-HAmbhd1T"
   },
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd09f0-e0e4-4389-9079-af1f52484e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, update your torch version\n",
    "# !uv pip uninstall torch\n",
    "# !uv pip install torch==2.10.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df8Bl47ZHe",
   "metadata": {
    "id": "32df8Bl47ZHe"
   },
   "outputs": [],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "num_epochs = 120\n",
    "for epoch in range(start_epoch, num_epochs + 1):\n",
    "    loss = train()\n",
    "    train_acc, _, _ = test(train_loader)\n",
    "    test_acc, _, _ = test(test_loader)\n",
    "    print(f\"Epoch {epoch:02d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "    # Step the scheduler based on the latest loss\n",
    "    scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e5085",
   "metadata": {},
   "source": [
    "**Display results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DbH_7JjsQLC9",
   "metadata": {
    "id": "DbH_7JjsQLC9"
   },
   "outputs": [],
   "source": [
    "# Rapport final\n",
    "_, all_preds, all_labels = test(test_loader)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=list(class_mapping.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9731ac0",
   "metadata": {},
   "source": [
    "**Save the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4a6c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    \"epoch\": epoch,\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    # hyperparams modèle\n",
    "    \"in_channels\": in_channels,\n",
    "    \"hidden_channels\": hidden_channels,\n",
    "    \"out_channels\": out_channels,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"dropout\": dropout,\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, \"improved_gnn_checkpoint.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
