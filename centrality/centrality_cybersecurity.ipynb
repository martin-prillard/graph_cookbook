{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Measures in Cybersecurity üîí\n",
    "\n",
    "Welcome to this comprehensive tutorial on centrality measures and their applications in cybersecurity! In this notebook, we'll explore how graph theory can be used to analyze network topologies, identify critical infrastructure, and detect vulnerabilities.\n",
    "\n",
    "## Concepts Covered:\n",
    "- **Centrality Measures**: Degree, Betweenness, Eigenvector, PageRank, Closeness\n",
    "- **Single Points of Failure (SPOF)**: Critical nodes and edges that could disrupt the network\n",
    "- **Cut-Vertices (Articulation Points)**: Nodes whose removal disconnects the network\n",
    "- **Bridges**: Edges whose removal disconnects the network\n",
    "- **Tarjan's Algorithm**: Efficient algorithm for finding cut-vertices and bridges\n",
    "- **Cybersecurity Applications**: Network security analysis, attack path identification, defense strategies\n",
    "\n",
    "## What You'll Learn:\n",
    "1. How to compute various centrality measures on network graphs\n",
    "2. How to identify critical infrastructure using graph analysis\n",
    "3. How hackers can use centrality to identify attack targets\n",
    "4. How blue teams can use centrality to protect their networks\n",
    "5. Visualizing network vulnerabilities and critical paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from collections import defaultdict, deque\n",
    "import random\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Generating a Realistic Corporate Network\n",
    "\n",
    "We'll create a realistic corporate network topology that represents:\n",
    "- **Core Infrastructure**: Main routers, switches, firewalls\n",
    "- **Departments**: IT, Finance, HR, Marketing, Engineering\n",
    "- **Servers**: Database servers, web servers, file servers\n",
    "- **Workstations**: Employee computers\n",
    "- **Network Devices**: Printers, IoT devices, access points\n",
    "\n",
    "This network will have enough complexity to demonstrate various centrality measures and vulnerabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corporate_network():\n",
    "    \"\"\"\n",
    "    Generate a realistic corporate network topology.\n",
    "    Returns a NetworkX graph representing a company's network infrastructure.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Core infrastructure (highly connected)\n",
    "    core_devices = [\n",
    "        'Core-Router-01', 'Core-Router-02', 'Core-Switch-01', \n",
    "        'Core-Switch-02', 'Firewall-01', 'Firewall-02',\n",
    "        'DMZ-Gateway', 'Internet-Gateway'\n",
    "    ]\n",
    "    \n",
    "    # Departments\n",
    "    departments = {\n",
    "        'IT': ['IT-Server-01', 'IT-Server-02', 'IT-Workstation-01', 'IT-Workstation-02', \n",
    "               'IT-Workstation-03', 'IT-Switch-01', 'IT-Printer-01'],\n",
    "        'Finance': ['Finance-Server-01', 'Finance-DB-01', 'Finance-Workstation-01', \n",
    "                   'Finance-Workstation-02', 'Finance-Workstation-03', 'Finance-Switch-01'],\n",
    "        'HR': ['HR-Server-01', 'HR-Workstation-01', 'HR-Workstation-02', \n",
    "               'HR-Workstation-03', 'HR-Switch-01'],\n",
    "        'Marketing': ['Marketing-Server-01', 'Marketing-Workstation-01', \n",
    "                     'Marketing-Workstation-02', 'Marketing-Workstation-03', \n",
    "                     'Marketing-Switch-01', 'Marketing-Printer-01'],\n",
    "        'Engineering': ['Eng-Server-01', 'Eng-Server-02', 'Eng-DB-01', \n",
    "                       'Eng-Workstation-01', 'Eng-Workstation-02', 'Eng-Workstation-03',\n",
    "                       'Eng-Workstation-04', 'Eng-Switch-01', 'Eng-Build-Server-01'],\n",
    "        'Executive': ['Exec-Server-01', 'Exec-Workstation-01', 'Exec-Workstation-02', \n",
    "                     'Exec-Switch-01'],\n",
    "        'Sales': ['Sales-Server-01', 'Sales-Workstation-01', 'Sales-Workstation-02',\n",
    "                 'Sales-Workstation-03', 'Sales-Switch-01']\n",
    "    }\n",
    "    \n",
    "    # Critical servers (high value targets)\n",
    "    critical_servers = [\n",
    "        'Domain-Controller-01', 'Domain-Controller-02', 'Email-Server-01',\n",
    "        'Backup-Server-01', 'File-Server-01', 'Web-Server-01', 'Web-Server-02',\n",
    "        'Database-Cluster-01', 'Database-Cluster-02'\n",
    "    ]\n",
    "    \n",
    "    # Network devices\n",
    "    network_devices = [\n",
    "        'Access-Point-01', 'Access-Point-02', 'Access-Point-03',\n",
    "        'VPN-Gateway-01', 'Load-Balancer-01', 'Proxy-Server-01'\n",
    "    ]\n",
    "    \n",
    "    # Add all nodes with attributes\n",
    "    G.add_nodes_from(core_devices, node_type='core', criticality='high')\n",
    "    G.add_nodes_from(critical_servers, node_type='server', criticality='critical')\n",
    "    \n",
    "    for dept, devices in departments.items():\n",
    "        for device in devices:\n",
    "            if 'Server' in device or 'DB' in device:\n",
    "                G.add_node(device, node_type='server', department=dept, criticality='high')\n",
    "            elif 'Workstation' in device:\n",
    "                G.add_node(device, node_type='workstation', department=dept, criticality='medium')\n",
    "            elif 'Switch' in device:\n",
    "                G.add_node(device, node_type='switch', department=dept, criticality='high')\n",
    "            else:\n",
    "                G.add_node(device, node_type='device', department=dept, criticality='low')\n",
    "    \n",
    "    G.add_nodes_from(network_devices, node_type='network', criticality='medium')\n",
    "    \n",
    "    # Create core network (highly connected mesh)\n",
    "    for i, node1 in enumerate(core_devices):\n",
    "        for node2 in core_devices[i+1:]:\n",
    "            if random.random() < 0.6:  # 60% connectivity in core\n",
    "                G.add_edge(node1, node2, weight=1, link_type='core')\n",
    "    \n",
    "    # Connect core to critical servers\n",
    "    for server in critical_servers:\n",
    "        # Each critical server connects to 2-3 core devices\n",
    "        connected_cores = random.sample(core_devices, min(3, len(core_devices)))\n",
    "        for core in connected_cores:\n",
    "            G.add_edge(server, core, weight=2, link_type='server-core')\n",
    "    \n",
    "    # Connect departments to core\n",
    "    for dept, devices in departments.items():\n",
    "        dept_switches = [d for d in devices if 'Switch' in d]\n",
    "        dept_servers = [d for d in devices if 'Server' in d or 'DB' in d]\n",
    "        dept_workstations = [d for d in devices if 'Workstation' in d]\n",
    "        dept_other = [d for d in devices if d not in dept_switches + dept_servers + dept_workstations]\n",
    "        \n",
    "        # Connect department switch to core\n",
    "        if dept_switches:\n",
    "            dept_switch = dept_switches[0]\n",
    "            # Connect to 2-3 core devices\n",
    "            connected_cores = random.sample(core_devices, min(3, len(core_devices)))\n",
    "            for core in connected_cores:\n",
    "                G.add_edge(dept_switch, core, weight=2, link_type='dept-core')\n",
    "        \n",
    "        # Connect servers to department switch or directly to core\n",
    "        for server in dept_servers:\n",
    "            if dept_switches and random.random() < 0.7:\n",
    "                G.add_edge(server, dept_switches[0], weight=1, link_type='server-switch')\n",
    "            else:\n",
    "                # Direct connection to core\n",
    "                core = random.choice(core_devices)\n",
    "                G.add_edge(server, core, weight=2, link_type='server-core')\n",
    "        \n",
    "        # Connect workstations to department switch\n",
    "        if dept_switches:\n",
    "            for workstation in dept_workstations:\n",
    "                G.add_edge(workstation, dept_switches[0], weight=1, link_type='workstation-switch')\n",
    "        \n",
    "        # Connect other devices\n",
    "        for device in dept_other:\n",
    "            if dept_switches:\n",
    "                G.add_edge(device, dept_switches[0], weight=1, link_type='device-switch')\n",
    "    \n",
    "    # Connect network devices to core\n",
    "    for device in network_devices:\n",
    "        if 'VPN' in device or 'Gateway' in device:\n",
    "            # VPN and gateways connect to multiple core devices\n",
    "            connected_cores = random.sample(core_devices, min(2, len(core_devices)))\n",
    "            for core in connected_cores:\n",
    "                G.add_edge(device, core, weight=2, link_type='network-core')\n",
    "        else:\n",
    "            # Other network devices connect to one core device\n",
    "            core = random.choice(core_devices)\n",
    "            G.add_edge(device, core, weight=2, link_type='network-core')\n",
    "    \n",
    "    # Add some inter-department connections (lower probability)\n",
    "    all_switches = [n for n in G.nodes() if 'Switch' in n]\n",
    "    for i, switch1 in enumerate(all_switches):\n",
    "        for switch2 in all_switches[i+1:]:\n",
    "            if random.random() < 0.15:  # 15% chance of inter-department connection\n",
    "                G.add_edge(switch1, switch2, weight=3, link_type='inter-dept')\n",
    "    \n",
    "    # Add some workstation-to-workstation connections (peer-to-peer, lower probability)\n",
    "    all_workstations = [n for n in G.nodes() if 'Workstation' in n]\n",
    "    for _ in range(len(all_workstations) // 10):  # ~10% of workstations have peer connections\n",
    "        ws1, ws2 = random.sample(all_workstations, 2)\n",
    "        if not G.has_edge(ws1, ws2):\n",
    "            G.add_edge(ws1, ws2, weight=5, link_type='peer')\n",
    "    \n",
    "    # Add attributes to edges if not present\n",
    "    for u, v in G.edges():\n",
    "        if 'weight' not in G[u][v]:\n",
    "            G[u][v]['weight'] = 1\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Generate the network\n",
    "print(\"Generating corporate network...\")\n",
    "G = generate_corporate_network()\n",
    "\n",
    "print(f\"\\n‚úÖ Network generated successfully!\")\n",
    "print(f\"   Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"   Edges: {G.number_of_edges()}\")\n",
    "print(f\"   Density: {nx.density(G):.4f}\")\n",
    "print(f\"   Is connected: {nx.is_connected(G)}\")\n",
    "print(f\"   Number of components: {nx.number_connected_components(G)}\")\n",
    "\n",
    "# Display node type distribution\n",
    "node_types = [G.nodes[n].get('node_type', 'unknown') for n in G.nodes()]\n",
    "type_counts = pd.Series(node_types).value_counts()\n",
    "print(f\"\\nüìä Node type distribution:\")\n",
    "for node_type, count in type_counts.items():\n",
    "    print(f\"   {node_type}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Centrality Measures\n",
    "\n",
    "Centrality measures help identify the most important nodes in a network. In cybersecurity, these measures can reveal:\n",
    "- **High-value targets** for attackers\n",
    "- **Critical infrastructure** that needs protection\n",
    "- **Bottlenecks** that could cause network disruption\n",
    "- **Influence propagation** paths for malware or attacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all centrality measures\n",
    "print(\"Computing centrality measures...\")\n",
    "\n",
    "# Degree Centrality: Number of connections\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Betweenness Centrality: How often a node lies on the shortest path between other nodes\n",
    "betweenness_centrality = nx.betweenness_centrality(G, weight='weight')\n",
    "\n",
    "# Closeness Centrality: How close a node is to all other nodes\n",
    "closeness_centrality = nx.closeness_centrality(G, distance='weight')\n",
    "\n",
    "# Eigenvector Centrality: Importance based on connections to important nodes\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000, weight='weight')\n",
    "\n",
    "# PageRank: Google's algorithm for ranking nodes\n",
    "pagerank = nx.pagerank(G, weight='weight')\n",
    "\n",
    "# Create a DataFrame with all centrality measures\n",
    "centrality_df = pd.DataFrame({\n",
    "    'node': list(G.nodes()),\n",
    "    'degree': [degree_centrality.get(n, 0) for n in G.nodes()],  # Normalized degree centrality\n",
    "    'degree_count': [G.degree(n) for n in G.nodes()],  # Actual degree count\n",
    "    'betweenness': [betweenness_centrality.get(n, 0) for n in G.nodes()],\n",
    "    'closeness': [closeness_centrality.get(n, 0) for n in G.nodes()],\n",
    "    'eigenvector': [eigenvector_centrality.get(n, 0) for n in G.nodes()],\n",
    "    'pagerank': [pagerank.get(n, 0) for n in G.nodes()],\n",
    "    'node_type': [G.nodes[n].get('node_type', 'unknown') for n in G.nodes()],\n",
    "    'department': [G.nodes[n].get('department', 'N/A') for n in G.nodes()],\n",
    "    'criticality': [G.nodes[n].get('criticality', 'medium') for n in G.nodes()]\n",
    "})\n",
    "\n",
    "# Sort by betweenness centrality (often most revealing for network topology)\n",
    "centrality_df = centrality_df.sort_values('betweenness', ascending=False)\n",
    "\n",
    "print(\"‚úÖ Centrality measures computed!\")\n",
    "print(f\"\\nüìä Top 10 nodes by Betweenness Centrality (network bottlenecks):\")\n",
    "print(centrality_df[['node', 'betweenness', 'degree_count', 'node_type', 'criticality']].head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_centrality(G, centrality_dict, title, node_size_multiplier=1000, figsize=(16, 12)):\n",
    "    \"\"\"\n",
    "    Plot network with nodes sized and colored by centrality measure.\n",
    "    \"\"\"\n",
    "    # Compute layout\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "    \n",
    "    # Prepare node sizes and colors\n",
    "    node_sizes = [centrality_dict.get(node, 0) * node_size_multiplier + 100 for node in G.nodes()]\n",
    "    node_colors = [centrality_dict.get(node, 0) for node in G.nodes()]\n",
    "    \n",
    "    # Get node types for coloring\n",
    "    node_types = [G.nodes[node].get('node_type', 'unknown') for node in G.nodes()]\n",
    "    type_to_color = {\n",
    "        'core': '#FF6B6B',      # Red\n",
    "        'server': '#4ECDC4',    # Teal\n",
    "        'workstation': '#95E1D3', # Light teal\n",
    "        'switch': '#F38181',    # Pink\n",
    "        'network': '#AA96DA',   # Purple\n",
    "        'device': '#FCBAD3'     # Light pink\n",
    "    }\n",
    "    node_colors_type = [type_to_color.get(nt, '#CCCCCC') for nt in node_types]\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.2, width=0.5, edge_color='gray')\n",
    "    \n",
    "    # Draw nodes by type (colored) and centrality (sized)\n",
    "    for node_type in set(node_types):\n",
    "        nodes_of_type = [node for node in G.nodes() if G.nodes[node].get('node_type') == node_type]\n",
    "        node_sizes_type = [centrality_dict.get(node, 0) * node_size_multiplier + 100 for node in nodes_of_type]\n",
    "        nx.draw_networkx_nodes(\n",
    "            G, pos,\n",
    "            nodelist=nodes_of_type,\n",
    "            node_size=node_sizes_type,\n",
    "            node_color=type_to_color.get(node_type, '#CCCCCC'),\n",
    "            alpha=0.8,\n",
    "            label=node_type\n",
    "        )\n",
    "    \n",
    "    # Draw labels for important nodes (top 10% by centrality)\n",
    "    sorted_nodes = sorted(centrality_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_nodes = [node for node, _ in sorted_nodes[:len(G.nodes())//10]]\n",
    "    labels = {node: node for node in top_nodes}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight='bold')\n",
    "    \n",
    "    plt.title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot with different centrality measures\n",
    "print(\"üìä Visualizing network with Degree Centrality...\")\n",
    "plot_network_centrality(G, degree_centrality, \n",
    "                       \"Network Topology - Node Size = Degree Centrality\\n(Larger nodes have more connections)\",\n",
    "                       node_size_multiplier=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Visualizing network with Betweenness Centrality...\")\n",
    "plot_network_centrality(G, betweenness_centrality,\n",
    "                       \"Network Topology - Node Size = Betweenness Centrality\\n(Larger nodes are critical bottlenecks)\",\n",
    "                       node_size_multiplier=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Comparing Centrality Measures\n",
    "\n",
    "Let's compare different centrality measures to understand which nodes are critical from different perspectives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=('Degree Centrality', 'Betweenness Centrality', 'Closeness Centrality',\n",
    "                   'Eigenvector Centrality', 'PageRank', 'Centrality Comparison'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "# Get top 15 nodes by each measure\n",
    "top_n = 15\n",
    "\n",
    "# Degree Centrality\n",
    "top_degree = centrality_df.nlargest(top_n, 'degree')\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_degree['node'], y=top_degree['degree'], name='Degree',\n",
    "           marker_color='#FF6B6B', text=top_degree['degree'].round(3),\n",
    "           textposition='outside'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Betweenness Centrality\n",
    "top_betweenness = centrality_df.nlargest(top_n, 'betweenness')\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_betweenness['node'], y=top_betweenness['betweenness'], name='Betweenness',\n",
    "           marker_color='#4ECDC4', text=top_betweenness['betweenness'].round(3),\n",
    "           textposition='outside'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Closeness Centrality\n",
    "top_closeness = centrality_df.nlargest(top_n, 'closeness')\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_closeness['node'], y=top_closeness['closeness'], name='Closeness',\n",
    "           marker_color='#95E1D3', text=top_closeness['closeness'].round(3),\n",
    "           textposition='outside'),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "# Eigenvector Centrality\n",
    "top_eigenvector = centrality_df.nlargest(top_n, 'eigenvector')\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_eigenvector['node'], y=top_eigenvector['eigenvector'], name='Eigenvector',\n",
    "           marker_color='#F38181', text=top_eigenvector['eigenvector'].round(3),\n",
    "           textposition='outside'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# PageRank\n",
    "top_pagerank = centrality_df.nlargest(top_n, 'pagerank')\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_pagerank['node'], y=top_pagerank['pagerank'], name='PageRank',\n",
    "           marker_color='#AA96DA', text=top_pagerank['pagerank'].round(4),\n",
    "           textposition='outside'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Scatter plot comparing betweenness vs degree\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=centrality_df['degree'],\n",
    "        y=centrality_df['betweenness'],\n",
    "        mode='markers+text',\n",
    "        text=centrality_df['node'],\n",
    "        textposition=\"top center\",\n",
    "        textfont=dict(size=8),\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=centrality_df['pagerank'],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"PageRank\", x=1.15)\n",
    "        ),\n",
    "        name='Nodes',\n",
    "        hovertemplate='<b>%{text}</b><br>Degree: %{x:.3f}<br>Betweenness: %{y:.3f}<extra></extra>'\n",
    "    ),\n",
    "    row=2, col=3\n",
    ")\n",
    "\n",
    "# Update x-axis labels\n",
    "for i in range(1, 3):\n",
    "    for j in range(1, 4):\n",
    "        fig.update_xaxes(tickangle=-45, row=i, col=j)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    showlegend=False,\n",
    "    title_text=\"Centrality Measures Comparison\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Node\", row=2, col=3)\n",
    "fig.update_yaxes(title_text=\"Betweenness\", row=2, col=3)\n",
    "fig.update_xaxes(title_text=\"Degree\", row=2, col=3)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Single Points of Failure (SPOF) Detection\n",
    "\n",
    "In cybersecurity, identifying Single Points of Failure (SPOF) is crucial. A SPOF is a component whose failure would cause the entire system to fail. In network graphs, these are:\n",
    "- **Cut-vertices (Articulation Points)**: Nodes whose removal disconnects the network\n",
    "- **Bridges**: Edges whose removal disconnects the network\n",
    "\n",
    "### Tarjan's Algorithm\n",
    "\n",
    "Tarjan's algorithm is an efficient algorithm for finding cut-vertices and bridges in a graph. It uses Depth-First Search (DFS) and runs in O(V + E) time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tarjan_cut_vertices(G):\n",
    "    \"\"\"\n",
    "    Find all articulation points (cut-vertices) in the graph using Tarjan's algorithm.\n",
    "    An articulation point is a vertex whose removal increases the number of connected components.\n",
    "    \n",
    "    Returns:\n",
    "        set: Set of articulation points\n",
    "    \"\"\"\n",
    "    if not nx.is_connected(G):\n",
    "        # For disconnected graphs, find articulation points in each component\n",
    "        articulation_points = set()\n",
    "        for component in nx.connected_components(G):\n",
    "            subgraph = G.subgraph(component)\n",
    "            articulation_points.update(tarjan_cut_vertices_connected(subgraph))\n",
    "        return articulation_points\n",
    "    \n",
    "    return tarjan_cut_vertices_connected(G)\n",
    "\n",
    "def tarjan_cut_vertices_connected(G):\n",
    "    \"\"\"\n",
    "    Find articulation points in a connected graph using Tarjan's algorithm.\n",
    "    \"\"\"\n",
    "    articulation_points = set()\n",
    "    discovery = {}\n",
    "    low = {}\n",
    "    parent = {}\n",
    "    time = [0]  # Use list to allow modification in nested function\n",
    "    \n",
    "    def dfs(u):\n",
    "        discovery[u] = time[0]\n",
    "        low[u] = time[0]\n",
    "        time[0] += 1\n",
    "        children = 0\n",
    "        \n",
    "        for v in G.neighbors(u):\n",
    "            if v not in discovery:\n",
    "                parent[v] = u\n",
    "                children += 1\n",
    "                dfs(v)\n",
    "                \n",
    "                # Update low value of u\n",
    "                low[u] = min(low[u], low[v])\n",
    "                \n",
    "                # u is an articulation point if:\n",
    "                # 1. It's the root and has more than one child\n",
    "                # 2. It's not the root and low[v] >= discovery[u]\n",
    "                if parent.get(u) is None and children > 1:\n",
    "                    articulation_points.add(u)\n",
    "                if parent.get(u) is not None and low[v] >= discovery[u]:\n",
    "                    articulation_points.add(u)\n",
    "            elif v != parent.get(u):\n",
    "                # Update low value of u for back edge\n",
    "                low[u] = min(low[u], discovery[v])\n",
    "    \n",
    "    # Start DFS from first node\n",
    "    if G.number_of_nodes() > 0:\n",
    "        start_node = list(G.nodes())[0]\n",
    "        parent[start_node] = None\n",
    "        dfs(start_node)\n",
    "    \n",
    "    return articulation_points\n",
    "\n",
    "def tarjan_bridges(G):\n",
    "    \"\"\"\n",
    "    Find all bridges (cut-edges) in the graph using Tarjan's algorithm.\n",
    "    A bridge is an edge whose removal increases the number of connected components.\n",
    "    \n",
    "    Returns:\n",
    "        set: Set of bridges (as tuples (u, v))\n",
    "    \"\"\"\n",
    "    if not nx.is_connected(G):\n",
    "        # For disconnected graphs, find bridges in each component\n",
    "        bridges = set()\n",
    "        for component in nx.connected_components(G):\n",
    "            subgraph = G.subgraph(component)\n",
    "            bridges.update(tarjan_bridges_connected(subgraph))\n",
    "        return bridges\n",
    "    \n",
    "    return tarjan_bridges_connected(G)\n",
    "\n",
    "def tarjan_bridges_connected(G):\n",
    "    \"\"\"\n",
    "    Find bridges in a connected graph using Tarjan's algorithm.\n",
    "    \"\"\"\n",
    "    bridges = set()\n",
    "    discovery = {}\n",
    "    low = {}\n",
    "    parent = {}\n",
    "    time = [0]\n",
    "    \n",
    "    def dfs(u):\n",
    "        discovery[u] = time[0]\n",
    "        low[u] = time[0]\n",
    "        time[0] += 1\n",
    "        \n",
    "        for v in G.neighbors(u):\n",
    "            if v not in discovery:\n",
    "                parent[v] = u\n",
    "                dfs(v)\n",
    "                \n",
    "                # Update low value of u\n",
    "                low[u] = min(low[u], low[v])\n",
    "                \n",
    "                # If low[v] > discovery[u], then (u, v) is a bridge\n",
    "                if low[v] > discovery[u]:\n",
    "                    # Add edge in canonical form (smaller node first)\n",
    "                    bridges.add(tuple(sorted([u, v])))\n",
    "            elif v != parent.get(u):\n",
    "                # Update low value of u for back edge\n",
    "                low[u] = min(low[u], discovery[v])\n",
    "    \n",
    "    # Start DFS from first node\n",
    "    if G.number_of_nodes() > 0:\n",
    "        start_node = list(G.nodes())[0]\n",
    "        parent[start_node] = None\n",
    "        dfs(start_node)\n",
    "    \n",
    "    return bridges\n",
    "\n",
    "# Find cut-vertices and bridges\n",
    "print(\"üîç Analyzing network for Single Points of Failure...\")\n",
    "cut_vertices = tarjan_cut_vertices(G)\n",
    "bridges = tarjan_bridges(G)\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis complete!\")\n",
    "print(f\"   Cut-vertices (Articulation Points): {len(cut_vertices)}\")\n",
    "print(f\"   Bridges (Cut-edges): {len(bridges)}\")\n",
    "\n",
    "if cut_vertices:\n",
    "    print(f\"\\n‚ö†Ô∏è  CRITICAL: Found {len(cut_vertices)} articulation points:\")\n",
    "    for i, vertex in enumerate(sorted(cut_vertices), 1):\n",
    "        node_type = G.nodes[vertex].get('node_type', 'unknown')\n",
    "        dept = G.nodes[vertex].get('department', 'N/A')\n",
    "        criticality = G.nodes[vertex].get('criticality', 'medium')\n",
    "        print(f\"   {i}. {vertex} (Type: {node_type}, Department: {dept}, Criticality: {criticality})\")\n",
    "\n",
    "if bridges:\n",
    "    print(f\"\\n‚ö†Ô∏è  CRITICAL: Found {len(bridges)} bridges:\")\n",
    "    for i, (u, v) in enumerate(sorted(bridges), 1):\n",
    "        print(f\"   {i}. {u} <-> {v}\")\n",
    "\n",
    "# Verify using NetworkX built-in function\n",
    "nx_cut_vertices = set(nx.articulation_points(G))\n",
    "nx_bridges = set(nx.bridges(G))\n",
    "\n",
    "print(f\"\\n‚úÖ Verification with NetworkX:\")\n",
    "print(f\"   NetworkX cut-vertices: {len(nx_cut_vertices)}\")\n",
    "print(f\"   NetworkX bridges: {len(nx_bridges)}\")\n",
    "print(f\"   Our algorithm matches: {cut_vertices == nx_cut_vertices}\")\n",
    "print(f\"   Our bridges match: {bridges == nx_bridges}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Visualizing SPOF\n",
    "\n",
    "Let's visualize the network highlighting cut-vertices and bridges to understand the vulnerabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spof_visualization(G, cut_vertices, bridges, figsize=(16, 12)):\n",
    "    \"\"\"\n",
    "    Visualize the network with cut-vertices and bridges highlighted.\n",
    "    \"\"\"\n",
    "    # Compute layout\n",
    "    pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Draw all edges first (non-bridges in light gray)\n",
    "    non_bridge_edges = [e for e in G.edges() if tuple(sorted(e)) not in bridges]\n",
    "    bridge_edges = [e for e in G.edges() if tuple(sorted(e)) in bridges]\n",
    "    \n",
    "    nx.draw_networkx_edges(G, pos, edgelist=non_bridge_edges, \n",
    "                          alpha=0.2, width=0.5, edge_color='gray', style='solid')\n",
    "    \n",
    "    # Draw bridges in red and thicker\n",
    "    if bridge_edges:\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=bridge_edges,\n",
    "                              alpha=0.8, width=3, edge_color='red', style='solid',\n",
    "                              label=f'Bridges ({len(bridges)})')\n",
    "    \n",
    "    # Draw non-cut-vertices\n",
    "    non_cut_vertices = [n for n in G.nodes() if n not in cut_vertices]\n",
    "    node_types = [G.nodes[n].get('node_type', 'unknown') for n in non_cut_vertices]\n",
    "    \n",
    "    type_to_color = {\n",
    "        'core': '#FF6B6B',\n",
    "        'server': '#4ECDC4',\n",
    "        'workstation': '#95E1D3',\n",
    "        'switch': '#F38181',\n",
    "        'network': '#AA96DA',\n",
    "        'device': '#FCBAD3'\n",
    "    }\n",
    "    \n",
    "    # Draw nodes by type\n",
    "    for node_type in set(node_types):\n",
    "        nodes_of_type = [n for n in non_cut_vertices \n",
    "                        if G.nodes[n].get('node_type') == node_type]\n",
    "        if nodes_of_type:\n",
    "            nx.draw_networkx_nodes(\n",
    "                G, pos,\n",
    "                nodelist=nodes_of_type,\n",
    "                node_size=300,\n",
    "                node_color=type_to_color.get(node_type, '#CCCCCC'),\n",
    "                alpha=0.6,\n",
    "                label=node_type\n",
    "            )\n",
    "    \n",
    "    # Draw cut-vertices in red with larger size\n",
    "    if cut_vertices:\n",
    "        nx.draw_networkx_nodes(\n",
    "            G, pos,\n",
    "            nodelist=list(cut_vertices),\n",
    "            node_size=800,\n",
    "            node_color='red',\n",
    "            alpha=0.9,\n",
    "            node_shape='s',  # Square shape for cut-vertices\n",
    "            label=f'Cut-vertices ({len(cut_vertices)})'\n",
    "        )\n",
    "        # Label cut-vertices\n",
    "        labels = {v: v for v in cut_vertices}\n",
    "        nx.draw_networkx_labels(G, pos, labels, font_size=8, \n",
    "                               font_weight='bold', font_color='white')\n",
    "    \n",
    "    plt.title('Network Topology with Single Points of Failure\\n'\n",
    "              'Red squares = Cut-vertices, Red edges = Bridges',\n",
    "              fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize SPOF\n",
    "print(\"üìä Visualizing Single Points of Failure...\")\n",
    "plot_spof_visualization(G, cut_vertices, bridges)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV: Cybersecurity Applications\n",
    "\n",
    "Now that we understand centrality measures and SPOF, let's explore how they can be used in cybersecurity contexts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Attacker's Perspective: Identifying High-Value Targets\n",
    "\n",
    "**How hackers can use centrality measures:**\n",
    "\n",
    "1. **Degree Centrality**: Identify highly connected nodes that provide access to many other systems\n",
    "2. **Betweenness Centrality**: Find critical bottlenecks that control information flow\n",
    "3. **Eigenvector Centrality**: Discover nodes connected to other important nodes (privilege escalation paths)\n",
    "4. **PageRank**: Identify influential nodes that could provide maximum network access\n",
    "5. **Cut-vertices**: Target nodes that, if compromised, could isolate parts of the network\n",
    "6. **Bridges**: Target critical links that, if severed, could disrupt network operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify high-value targets from attacker's perspective\n",
    "print(\"üéØ ATTACKER'S PERSPECTIVE: High-Value Targets\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine multiple metrics to identify top targets\n",
    "centrality_df['is_cut_vertex'] = centrality_df['node'].isin(cut_vertices)\n",
    "centrality_df['threat_score'] = (\n",
    "    centrality_df['betweenness'] * 0.3 +\n",
    "    centrality_df['degree'] * 0.2 +\n",
    "    centrality_df['eigenvector'] * 0.2 +\n",
    "    centrality_df['pagerank'] * 0.15 +\n",
    "    centrality_df['closeness'] * 0.15 +\n",
    "    centrality_df['is_cut_vertex'].astype(int) * 0.1  # Bonus for cut-vertices\n",
    ")\n",
    "\n",
    "# Sort by threat score\n",
    "top_targets = centrality_df.nlargest(15, 'threat_score')\n",
    "\n",
    "print(\"\\nüî• TOP 15 HIGH-VALUE TARGETS (Attacker's Priority):\")\n",
    "print(\"-\" * 60)\n",
    "for idx, row in top_targets.iterrows():\n",
    "    print(f\"\\n{top_targets.index.get_loc(idx) + 1}. {row['node']}\")\n",
    "    print(f\"   Threat Score: {row['threat_score']:.4f}\")\n",
    "    print(f\"   Type: {row['node_type']}, Department: {row['department']}\")\n",
    "    print(f\"   Criticality: {row['criticality']}\")\n",
    "    print(f\"   Cut-vertex: {'‚ö†Ô∏è YES' if row['is_cut_vertex'] else 'No'}\")\n",
    "    print(f\"   Betweenness: {row['betweenness']:.4f}, Degree Count: {row['degree_count']}\")\n",
    "    print(f\"   Attack Impact: \", end=\"\")\n",
    "    if row['is_cut_vertex']:\n",
    "        print(\"HIGH - Network isolation possible\")\n",
    "    elif row['betweenness'] > 0.1:\n",
    "        print(\"HIGH - Critical bottleneck\")\n",
    "    elif row['degree_count'] > 15:\n",
    "        print(\"MEDIUM - High connectivity\")\n",
    "    else:\n",
    "        print(\"LOW - Limited impact\")\n",
    "\n",
    "# Create visualization of attack targets\n",
    "fig = go.Figure()\n",
    "\n",
    "# Scatter plot: Threat score vs Betweenness\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=centrality_df['betweenness'],\n",
    "    y=centrality_df['threat_score'],\n",
    "    mode='markers+text',\n",
    "    text=centrality_df['node'],\n",
    "    textposition=\"top center\",\n",
    "    textfont=dict(size=8),\n",
    "    marker=dict(\n",
    "        size=centrality_df['degree_count'] * 8 + 10,\n",
    "        color=centrality_df['is_cut_vertex'].astype(int),\n",
    "        colorscale=['#4ECDC4', 'red'],\n",
    "        showscale=True,\n",
    "        colorbar=dict(title=\"Is Cut-vertex\", tickvals=[0, 1], ticktext=['No', 'Yes']),\n",
    "        line=dict(width=2, color='white')\n",
    "    ),\n",
    "    hovertemplate='<b>%{text}</b><br>'\n",
    "                  'Threat Score: %{y:.4f}<br>'\n",
    "                  'Betweenness: %{x:.4f}<br>'\n",
    "                  'Degree Count: %{marker.size:.0f}<extra></extra>',\n",
    "    name='Nodes'\n",
    "))\n",
    "\n",
    "# Highlight top targets\n",
    "for idx, row in top_targets.head(5).iterrows():\n",
    "    fig.add_annotation(\n",
    "        x=row['betweenness'],\n",
    "        y=row['threat_score'],\n",
    "        text=row['node'],\n",
    "        showarrow=True,\n",
    "        arrowhead=2,\n",
    "        arrowsize=1,\n",
    "        arrowwidth=2,\n",
    "        arrowcolor=\"red\",\n",
    "        ax=20,\n",
    "        ay=-40,\n",
    "        font=dict(size=10, color=\"red\", family=\"Arial Black\")\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Attack Target Analysis: Threat Score vs Betweenness Centrality<br>'\n",
    "          '<sub>Size = Degree, Color = Cut-vertex (red), Top 5 targets annotated</sub>',\n",
    "    xaxis_title='Betweenness Centrality',\n",
    "    yaxis_title='Threat Score',\n",
    "    height=700,\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Defender's Perspective: Protection Strategy\n",
    "\n",
    "**How blue teams can use centrality measures:**\n",
    "\n",
    "1. **Identify Critical Infrastructure**: Protect nodes with high centrality measures\n",
    "2. **Redundancy Planning**: Add redundancy for cut-vertices and bridges\n",
    "3. **Monitoring Priority**: Focus monitoring on high-centrality nodes\n",
    "4. **Access Control**: Implement stricter access controls on critical nodes\n",
    "5. **Network Segmentation**: Use centrality to plan network segmentation\n",
    "6. **Incident Response**: Prioritize response based on node criticality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense strategy recommendations\n",
    "print(\"üõ°Ô∏è DEFENDER'S PERSPECTIVE: Protection Strategy\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Identify nodes that need protection\n",
    "protection_priority = centrality_df.copy()\n",
    "protection_priority['protection_priority'] = (\n",
    "    protection_priority['threat_score'] * 0.5 +  # High threat = high priority\n",
    "    protection_priority['is_cut_vertex'].astype(int) * 0.3 +  # Cut-vertices critical\n",
    "    (protection_priority['criticality'] == 'critical').astype(int) * 0.2  # Marked critical\n",
    ")\n",
    "\n",
    "top_protect = protection_priority.nlargest(15, 'protection_priority')\n",
    "\n",
    "print(\"\\nüîí TOP 15 NODES REQUIRING PROTECTION:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "for idx, row in top_protect.iterrows():\n",
    "    node = row['node']\n",
    "    node_type = row['node_type']\n",
    "    is_cut = row['is_cut_vertex']\n",
    "    \n",
    "    print(f\"\\n{top_protect.index.get_loc(idx) + 1}. {node}\")\n",
    "    print(f\"   Protection Priority: {row['protection_priority']:.4f}\")\n",
    "    print(f\"   Type: {node_type}, Criticality: {row['criticality']}\")\n",
    "    \n",
    "    # Generate recommendations\n",
    "    recs = []\n",
    "    \n",
    "    if is_cut:\n",
    "        recs.append(\"‚ö†Ô∏è CRITICAL: Add redundant connections (remove cut-vertex status)\")\n",
    "        recs.append(\"   - Implement load balancing\")\n",
    "        recs.append(\"   - Add backup systems\")\n",
    "    \n",
    "    if row['betweenness'] > 0.1:\n",
    "        recs.append(\"üîç High monitoring priority (bottleneck)\")\n",
    "        recs.append(\"   - Implement 24/7 monitoring\")\n",
    "        recs.append(\"   - Set up alerts for anomalies\")\n",
    "    \n",
    "    if node_type == 'core' or node_type == 'server':\n",
    "        recs.append(\"üîê Stricter access controls\")\n",
    "        recs.append(\"   - Multi-factor authentication\")\n",
    "        recs.append(\"   - Principle of least privilege\")\n",
    "        recs.append(\"   - Regular security audits\")\n",
    "    \n",
    "    if row['degree_count'] > 15:\n",
    "        recs.append(\"üåê Network segmentation\")\n",
    "        recs.append(\"   - Isolate from less critical systems\")\n",
    "        recs.append(\"   - Implement firewall rules\")\n",
    "    \n",
    "    recommendations.append({\n",
    "        'node': node,\n",
    "        'priority': row['protection_priority'],\n",
    "        'recommendations': recs\n",
    "    })\n",
    "    \n",
    "    for rec in recs[:3]:  # Show first 3 recommendations\n",
    "        print(f\"   {rec}\")\n",
    "\n",
    "# Create protection priority visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Protection Priority Ranking', 'Cut-vertices Analysis',\n",
    "                   'Betweenness vs Protection Priority', 'Node Type Protection Needs'),\n",
    "    specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
    "           [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
    ")\n",
    "\n",
    "# Protection priority bar chart\n",
    "top_15_protect = protection_priority.nlargest(15, 'protection_priority')\n",
    "fig.add_trace(\n",
    "    go.Bar(x=top_15_protect['node'], y=top_15_protect['protection_priority'],\n",
    "           name='Protection Priority', marker_color='#FF6B6B',\n",
    "           text=top_15_protect['protection_priority'].round(3),\n",
    "           textposition='outside'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Cut-vertices analysis\n",
    "cut_vertex_df = centrality_df[centrality_df['is_cut_vertex']].copy()\n",
    "if len(cut_vertex_df) > 0:\n",
    "    fig.add_trace(\n",
    "        go.Bar(x=cut_vertex_df['node'], y=cut_vertex_df['betweenness'],\n",
    "               name='Cut-vertices Betweenness', marker_color='red',\n",
    "               text=cut_vertex_df['betweenness'].round(3),\n",
    "               textposition='outside'),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Scatter: Betweenness vs Protection Priority\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=protection_priority['betweenness'],\n",
    "        y=protection_priority['protection_priority'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=protection_priority['degree_count'] * 5 + 5,\n",
    "            color=protection_priority['is_cut_vertex'].astype(int),\n",
    "            colorscale=['#4ECDC4', 'red'],\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Cut-vertex\", x=1.15, tickvals=[0, 1], ticktext=['No', 'Yes']),\n",
    "            line=dict(width=1, color='white')\n",
    "        ),\n",
    "        text=protection_priority['node'],\n",
    "        hovertemplate='<b>%{text}</b><br>'\n",
    "                      'Protection Priority: %{y:.4f}<br>'\n",
    "                      'Betweenness: %{x:.4f}<extra></extra>',\n",
    "        name='Nodes'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Node type protection needs\n",
    "type_protection = protection_priority.groupby('node_type')['protection_priority'].mean().sort_values(ascending=False)\n",
    "fig.add_trace(\n",
    "    go.Bar(x=type_protection.index, y=type_protection.values,\n",
    "           name='Avg Protection Priority by Type', marker_color='#AA96DA',\n",
    "           text=type_protection.values.round(3),\n",
    "           textposition='outside'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "for i in range(1, 3):\n",
    "    for j in range(1, 3):\n",
    "        fig.update_xaxes(tickangle=-45, row=i, col=j)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    showlegend=False,\n",
    "    title_text=\"Defense Strategy Analysis\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Node\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Protection Priority\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Betweenness\", row=2, col=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Attack Path Analysis\n",
    "\n",
    "Let's analyze potential attack paths using centrality measures. An attacker might:\n",
    "1. Start from a low-security node (workstation)\n",
    "2. Move through high-betweenness nodes (bottlenecks)\n",
    "3. Target cut-vertices to isolate network segments\n",
    "4. Reach high-value targets (servers, domain controllers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate attack paths\n",
    "def find_attack_paths(G, start_node, target_node, max_paths=5):\n",
    "    \"\"\"\n",
    "    Find potential attack paths from a starting node to a target node.\n",
    "    Prioritizes paths through high-betweenness nodes and cut-vertices.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Find all simple paths\n",
    "        paths = list(nx.all_simple_paths(G, start_node, target_node, cutoff=10))[:max_paths]\n",
    "        \n",
    "        # Score paths based on vulnerability\n",
    "        scored_paths = []\n",
    "        for path in paths:\n",
    "            score = 0\n",
    "            cut_vertices_in_path = sum(1 for n in path if n in cut_vertices)\n",
    "            high_betweenness_nodes = sum(1 for n in path \n",
    "                                        if centrality_df[centrality_df['node'] == n]['betweenness'].values[0] > 0.1)\n",
    "            \n",
    "            # Paths through cut-vertices are more dangerous\n",
    "            score += cut_vertices_in_path * 10\n",
    "            # Paths through high-betweenness nodes are more likely\n",
    "            score += high_betweenness_nodes * 5\n",
    "            # Shorter paths are more likely\n",
    "            score += (11 - len(path)) * 2\n",
    "            \n",
    "            scored_paths.append((path, score, cut_vertices_in_path, high_betweenness_nodes))\n",
    "        \n",
    "        # Sort by score (higher is more dangerous/likely)\n",
    "        scored_paths.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scored_paths\n",
    "    except nx.NetworkXNoPath:\n",
    "        return []\n",
    "\n",
    "# Find attack paths from a workstation to a domain controller\n",
    "workstations = [n for n in G.nodes() if 'Workstation' in n and G.nodes[n].get('node_type') == 'workstation']\n",
    "domain_controllers = [n for n in G.nodes() if 'Domain-Controller' in n]\n",
    "\n",
    "if workstations and domain_controllers:\n",
    "    start = workstations[0]  # Attacker's entry point\n",
    "    target = domain_controllers[0]  # High-value target\n",
    "    \n",
    "    print(f\"üéØ ATTACK PATH ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"From: {start} (Potential entry point)\")\n",
    "    print(f\"To: {target} (High-value target: Domain Controller)\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    attack_paths = find_attack_paths(G, start, target, max_paths=5)\n",
    "    \n",
    "    if attack_paths:\n",
    "        print(f\"\\nFound {len(attack_paths)} potential attack paths:\\n\")\n",
    "        for i, (path, score, cut_count, high_bet_count) in enumerate(attack_paths, 1):\n",
    "            print(f\"Path {i} (Danger Score: {score}):\")\n",
    "            print(f\"  {' -> '.join(path)}\")\n",
    "            print(f\"  Length: {len(path) - 1} hops\")\n",
    "            print(f\"  Cut-vertices: {cut_count}, High-betweenness nodes: {high_bet_count}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"\\nNo direct path found (network segmentation working!)\")\n",
    "    \n",
    "    # Visualize attack path\n",
    "    if attack_paths:\n",
    "        best_path = attack_paths[0][0]\n",
    "        \n",
    "        # Create visualization\n",
    "        pos = nx.spring_layout(G, k=2, iterations=50, seed=42)\n",
    "        \n",
    "        plt.figure(figsize=(16, 12))\n",
    "        \n",
    "        # Draw all edges\n",
    "        nx.draw_networkx_edges(G, pos, alpha=0.1, width=0.3, edge_color='gray')\n",
    "        \n",
    "        # Highlight attack path\n",
    "        path_edges = [(best_path[i], best_path[i+1]) for i in range(len(best_path)-1)]\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=path_edges, \n",
    "                              alpha=0.8, width=4, edge_color='red', style='dashed',\n",
    "                              label='Attack Path')\n",
    "        \n",
    "        # Draw all nodes\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=200, node_color='lightblue', alpha=0.6)\n",
    "        \n",
    "        # Highlight path nodes\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=best_path,\n",
    "                              node_size=500, node_color='red', alpha=0.8,\n",
    "                              label='Path Nodes')\n",
    "        \n",
    "        # Highlight start and target\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=[start],\n",
    "                              node_size=800, node_color='orange', alpha=0.9,\n",
    "                              node_shape='s', label='Start (Entry)')\n",
    "        nx.draw_networkx_nodes(G, pos, nodelist=[target],\n",
    "                              node_size=800, node_color='darkred', alpha=0.9,\n",
    "                              node_shape='s', label='Target (Domain Controller)')\n",
    "        \n",
    "        # Label important nodes\n",
    "        labels = {start: 'START', target: 'TARGET'}\n",
    "        labels.update({n: n for n in best_path if n in cut_vertices})\n",
    "        nx.draw_networkx_labels(G, pos, labels, font_size=8, font_weight='bold')\n",
    "        \n",
    "        plt.title(f'Attack Path Analysis: {start} ‚Üí {target}\\n'\n",
    "                 f'Path through {len(best_path)-1} hops, Danger Score: {attack_paths[0][1]}',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Could not find suitable nodes for attack path analysis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part V: Summary and Key Insights\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Centrality Measures** help identify critical nodes from different perspectives:\n",
    "   - **Degree**: Highly connected nodes (many attack surfaces)\n",
    "   - **Betweenness**: Network bottlenecks (critical for information flow)\n",
    "   - **Eigenvector**: Nodes connected to important nodes (privilege escalation)\n",
    "   - **PageRank**: Influential nodes (maximum network access)\n",
    "   - **Closeness**: Centrally located nodes (fast propagation)\n",
    "\n",
    "2. **Single Points of Failure (SPOF)**:\n",
    "   - **Cut-vertices**: Removing these nodes disconnects the network\n",
    "   - **Bridges**: Removing these edges disconnects the network\n",
    "   - Critical for both attackers (targets) and defenders (protection priority)\n",
    "\n",
    "3. **Cybersecurity Applications**:\n",
    "   - **Attackers**: Use centrality to identify high-value targets and attack paths\n",
    "   - **Defenders**: Use centrality to prioritize protection and monitoring\n",
    "   - **Network Design**: Identify and eliminate SPOF through redundancy\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **For Network Administrators**:\n",
    "   - Identify all cut-vertices and bridges\n",
    "   - Add redundancy to eliminate SPOF\n",
    "   - Implement monitoring on high-centrality nodes\n",
    "   - Use network segmentation based on centrality analysis\n",
    "\n",
    "2. **For Security Teams**:\n",
    "   - Prioritize protection of high-centrality nodes\n",
    "   - Monitor attack paths through cut-vertices\n",
    "   - Implement stricter access controls on critical nodes\n",
    "   - Regular centrality analysis to identify new vulnerabilities\n",
    "\n",
    "3. **For Incident Response**:\n",
    "   - Respond first to incidents on high-centrality nodes\n",
    "   - Isolate cut-vertices if compromised\n",
    "   - Trace attack paths using centrality measures\n",
    "   - Use betweenness to identify lateral movement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive summary dashboard\n",
    "print(\"üìä NETWORK SECURITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìà Network Statistics:\")\n",
    "print(f\"   Total Nodes: {G.number_of_nodes()}\")\n",
    "print(f\"   Total Edges: {G.number_of_edges()}\")\n",
    "print(f\"   Network Density: {nx.density(G):.4f}\")\n",
    "print(f\"   Average Clustering: {nx.average_clustering(G):.4f}\")\n",
    "print(f\"   Diameter: {nx.diameter(G) if nx.is_connected(G) else 'N/A (disconnected)'}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Vulnerability Assessment:\")\n",
    "print(f\"   Cut-vertices (SPOF): {len(cut_vertices)}\")\n",
    "print(f\"   Bridges (SPOF): {len(bridges)}\")\n",
    "print(f\"   High-betweenness nodes (>0.1): {len(centrality_df[centrality_df['betweenness'] > 0.1])}\")\n",
    "print(f\"   High-degree nodes (>15): {len(centrality_df[centrality_df['degree_count'] > 15])}\")\n",
    "\n",
    "print(f\"\\nüéØ Top 5 Attack Targets:\")\n",
    "top_targets_summary = centrality_df.nlargest(5, 'threat_score')\n",
    "for i, (idx, row) in enumerate(top_targets_summary.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['node']} (Threat Score: {row['threat_score']:.4f})\")\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è  Top 5 Protection Priorities:\")\n",
    "top_protect_summary = protection_priority.nlargest(5, 'protection_priority')\n",
    "for i, (idx, row) in enumerate(top_protect_summary.iterrows(), 1):\n",
    "    print(f\"   {i}. {row['node']} (Priority: {row['protection_priority']:.4f})\")\n",
    "\n",
    "print(f\"\\nüí° Key Recommendations:\")\n",
    "print(f\"   1. Add redundancy to {len(cut_vertices)} cut-vertices\")\n",
    "print(f\"   2. Protect {len(bridges)} bridge connections\")\n",
    "print(f\"   3. Implement monitoring on top {len(top_targets_summary)} high-value targets\")\n",
    "print(f\"   4. Review network segmentation around high-betweenness nodes\")\n",
    "print(f\"   5. Regular centrality analysis to detect topology changes\")\n",
    "\n",
    "# Create final summary visualization\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=('Network Vulnerability Map', 'Centrality Distribution',\n",
    "                   'Node Type Risk Analysis', 'Protection vs Threat Score'),\n",
    "    specs=[[{\"type\": \"scatter\"}, {\"type\": \"histogram\"}],\n",
    "           [{\"type\": \"bar\"}, {\"type\": \"scatter\"}]]\n",
    ")\n",
    "\n",
    "# Vulnerability map: Betweenness vs Degree Count, colored by cut-vertex status\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=centrality_df['degree_count'],\n",
    "        y=centrality_df['betweenness'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=10,\n",
    "            color=centrality_df['is_cut_vertex'].astype(int),\n",
    "            colorscale=['#4ECDC4', 'red'],\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Cut-vertex\", x=1.02, tickvals=[0, 1], ticktext=['No', 'Yes']),\n",
    "            line=dict(width=1, color='white')\n",
    "        ),\n",
    "        text=centrality_df['node'],\n",
    "        hovertemplate='<b>%{text}</b><br>Degree Count: %{x}<br>Betweenness: %{y:.4f}<extra></extra>',\n",
    "        name='Nodes'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Betweenness distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(x=centrality_df['betweenness'], nbinsx=20, name='Betweenness',\n",
    "                marker_color='#4ECDC4'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Node type risk analysis\n",
    "type_risk = centrality_df.groupby('node_type').agg({\n",
    "    'threat_score': 'mean',\n",
    "    'is_cut_vertex': 'sum'\n",
    "}).sort_values('threat_score', ascending=False)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x=type_risk.index, y=type_risk['threat_score'],\n",
    "           name='Avg Threat Score', marker_color='#FF6B6B',\n",
    "           text=type_risk['threat_score'].round(3),\n",
    "           textposition='outside'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Protection vs Threat\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=protection_priority['threat_score'],\n",
    "        y=protection_priority['protection_priority'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=8,\n",
    "            color=protection_priority['is_cut_vertex'].astype(int),\n",
    "            colorscale=['#95E1D3', 'red'],\n",
    "            showscale=False,\n",
    "            line=dict(width=1, color='white')\n",
    "        ),\n",
    "        text=protection_priority['node'],\n",
    "        hovertemplate='<b>%{text}</b><br>Threat: %{x:.4f}<br>Protection: %{y:.4f}<extra></extra>',\n",
    "        name='Nodes'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_xaxes(title_text=\"Degree Count\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Betweenness\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Betweenness Centrality\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"Node Type\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Average Threat Score\", row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Threat Score\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Protection Priority\", row=2, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    showlegend=False,\n",
    "    title_text=\"Network Security Analysis Dashboard\",\n",
    "    title_x=0.5\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete! Review the visualizations above for detailed insights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
