{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "128744db",
   "metadata": {},
   "source": [
    "# Community Detection Tutorial üï∏Ô∏è\n",
    "\n",
    "Welcome to this comprehensive tutorial on community detection in graphs! In this notebook, we'll explore different methods to identify communities (clusters) in network graphs.\n",
    "\n",
    "## Concepts Covered:\n",
    "- **Community Detection**: Finding groups of nodes that are more densely connected to each other than to the rest of the network\n",
    "- **Node Embedding**: Converting graph nodes into vector representations that capture structural relationships\n",
    "- **Clustering Algorithms**: Grouping nodes based on their embeddings or structural properties\n",
    "- **Dimension Reduction**: Visualizing high-dimensional embeddings in 2D space\n",
    "\n",
    "Community detection can help identify:\n",
    "- Groups of users with similar interests or connections\n",
    "- Potential targets for targeted marketing or content\n",
    "- Information flow patterns and influence propagation\n",
    "- Network resilience and critical nodes\n",
    "\n",
    "## What You'll Learn:\n",
    "1. Graph-based community detection (Girvan-Newman, Louvain algorithms)\n",
    "2. Node embedding techniques (Node2Vec)\n",
    "3. Visualizing communities in 2D using t-SNE\n",
    "4. Comparing different clustering approaches\n",
    "5. Evaluating community quality with metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ec182",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import warnings\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "from node2vec import Node2Vec\n",
    "from openTSNE import TSNE\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.cluster import DBSCAN, KMeans, OPTICS\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcaefb7",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Let's define some helper functions for formatting and visualizing communities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49885d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_comp(comp):\n",
    "    \"\"\"\n",
    "    Convert a list of communities into a partition dictionary.\n",
    "    \n",
    "    Args:\n",
    "        comp: List of communities, where each community is a list of nodes\n",
    "        \n",
    "    Returns:\n",
    "        partition: Dictionary mapping node -> community_id\n",
    "    \"\"\"\n",
    "    partition = {}\n",
    "    for id_cluster, community in enumerate(comp):\n",
    "        for user in community:\n",
    "            partition[user] = id_cluster + 1\n",
    "    return partition\n",
    "\n",
    "def plot_graph_with_communities(G, partition, title=\"Graph with Communities\", figsize=(12, 8)):\n",
    "    \"\"\"\n",
    "    Visualize a graph with nodes colored by their community membership.\n",
    "    Each community gets a distinct color.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        partition: Either:\n",
    "            - List (or iterable) of sets of nodes, as returned by nx.community.louvain_communities\n",
    "            - Dictionary mapping node -> community_id\n",
    "        title: Plot title\n",
    "        figsize: Figure size tuple\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Compute layout for nodes\n",
    "    pos = nx.layout.forceatlas2_layout(G)\n",
    "    \n",
    "    # Handle different partition formats\n",
    "    if isinstance(partition, dict):\n",
    "        # Partition is already a dictionary: node -> community_id\n",
    "        node_to_comm_raw = partition\n",
    "    else:\n",
    "        # Partition is a list of sets: convert to dictionary\n",
    "        node_to_comm_raw = {}\n",
    "        for comm_id, community in enumerate(partition):\n",
    "            for node in community:\n",
    "                node_to_comm_raw[node] = comm_id\n",
    "    \n",
    "    # Normalize community IDs to be sequential (0, 1, 2, ...)\n",
    "    # This ensures each community gets a distinct color from the colormap\n",
    "    unique_comm_ids = sorted(set(node_to_comm_raw.values()))\n",
    "    comm_id_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_comm_ids)}\n",
    "    node_to_comm = {node: comm_id_mapping[comm_id] for node, comm_id in node_to_comm_raw.items()}\n",
    "    \n",
    "    # Get number of communities (after normalization)\n",
    "    num_communities = len(unique_comm_ids)\n",
    "    \n",
    "    # Choose colormap based on number of communities\n",
    "    # Use tab20 for up to 20 communities, otherwise use a larger colormap\n",
    "    if num_communities <= 20:\n",
    "        cmap = plt.cm.get_cmap('tab20')\n",
    "    elif num_communities <= 40:\n",
    "        # Combine tab20 twice for more colors\n",
    "        colors1 = plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "        colors2 = plt.cm.tab20b(np.linspace(0, 1, 20))\n",
    "        from matplotlib.colors import ListedColormap\n",
    "        cmap = ListedColormap(np.vstack([colors1, colors2]))\n",
    "    else:\n",
    "        # Use a continuous colormap for many communities\n",
    "        cmap = plt.cm.get_cmap('nipy_spectral')\n",
    "    \n",
    "    # Assign color to each node based on its community\n",
    "    node_colors = [node_to_comm.get(node, -1) for node in G.nodes()]\n",
    "    \n",
    "    # Draw nodes with proper color scaling\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        node_size=100,\n",
    "        node_color=node_colors,\n",
    "        cmap=cmap,\n",
    "        vmin=-0.5,  # Slightly below 0 to handle missing nodes\n",
    "        vmax=num_communities - 0.5,  # Slightly above max to center colors\n",
    "        alpha=0.85\n",
    "    )\n",
    "    \n",
    "    # Draw edges\n",
    "    nx.draw_networkx_edges(G, pos, alpha=0.3, width=0.5)\n",
    "    \n",
    "    # Optionally draw labels for small graphs\n",
    "    if len(G.nodes()) < 50:\n",
    "        nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_community_stats(G, partition, name=\"Community\"):\n",
    "    \"\"\"\n",
    "    Print statistics about the detected communities.\n",
    "    \n",
    "    Args:\n",
    "        G: NetworkX graph\n",
    "        partition: List (or iterable) of sets of nodes, as returned by nx.community.louvain_communities\n",
    "        name: Name prefix for the statistics\n",
    "    \"\"\"\n",
    "    # Build a mapping node -> community_id for convenience\n",
    "    node_to_comm = {}\n",
    "    for comm_id, community in enumerate(partition):\n",
    "        for node in community:\n",
    "            node_to_comm[node] = comm_id\n",
    "\n",
    "    print(f\"\\n{name} Statistics:\")\n",
    "    print(f\"  Total nodes: {len(G.nodes())}\")\n",
    "    print(f\"  Total edges: {len(G.edges())}\")\n",
    "    print(f\"  Number of communities: {len(partition)}\")\n",
    "    print(f\"\\n  Community sizes:\")\n",
    "    for comm_id, community in enumerate(partition):\n",
    "        print(f\"    {name} {comm_id}: {len(community)} nodes\")\n",
    "        if len(community) <= 10:\n",
    "            print(f\"      Nodes: {', '.join(str(n) for n in list(community)[:10])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ae9d0f",
   "metadata": {},
   "source": [
    "### Load the Les Mis√©rables character co-occurrence network\n",
    "###### This network represents characters that appear together in scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9204d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "G2 = nx.read_gml(\"../../data/lesmiserables.gml\")\n",
    "\n",
    "print(f\"Graph loaded: {len(G2.nodes())} nodes, {len(G2.edges())} edges\")\n",
    "print(f\"Graph density: {nx.density(G2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31fa2ca",
   "metadata": {},
   "source": [
    "### Apply Girvan-Newman algorithm\n",
    "\n",
    "Note: This returns an iterator, so we convert to list to see all levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f8d70e-27d9-4006-9f86-21fbcb44e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat /opt/venv/lib/python3.11/site-packages/networkx/algorithms/community/centrality.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3181024",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = list(nx.algorithms.community.centrality.girvan_newman(G2))\n",
    "print(f\"\\nNumber of decomposition levels: {len(comp)}\")\n",
    "print(f\"Each level shows a different granularity of communities\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d8dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different levels of the dendrogram\n",
    "max_cluster = 10\n",
    "print(\"Visualizing different levels of community decomposition:\\n\")\n",
    "\n",
    "for level_dendrogramme, clusters in enumerate(comp):\n",
    "    if level_dendrogramme + 1 >= max_cluster:\n",
    "        break\n",
    "    \n",
    "    comp_formatted = tuple(sorted(c) for c in clusters)\n",
    "    partition = format_comp(comp_formatted)\n",
    "    \n",
    "    print(f\"Level {level_dendrogramme + 1}: {len(clusters)} communities\")\n",
    "    plot_graph_with_communities(\n",
    "        G2, \n",
    "        partition, \n",
    "        title=f\"Girvan-Newman Level {level_dendrogramme + 1} - {len(clusters)} Communities\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a199e610",
   "metadata": {},
   "source": [
    "## 1.2 Louvain Algorithm\n",
    "\n",
    "The **Louvain algorithm** is a fast, heuristic method for community detection that optimizes modularity. It's one of the most popular community detection algorithms because it:\n",
    "- Runs in near-linear time on sparse graphs\n",
    "- Produces high-quality communities\n",
    "- Can handle very large networks\n",
    "\n",
    "### How it Works:\n",
    "1. Starts with each node in its own community\n",
    "2. Iteratively moves nodes to neighboring communities if it increases modularity\n",
    "3. Aggregates communities into super-nodes\n",
    "4. Repeats until no improvement is possible\n",
    "\n",
    "### Modularity:\n",
    "Modularity measures how much more densely connected nodes are within communities compared to a random network. Values range from -1 to 1, with higher values indicating stronger community structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba506f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Game of Thrones character interaction network\n",
    "# This dataset contains character interactions across all 8 seasons\n",
    "df = pd.read_csv('../../data/got-s1-8-edges.csv')\n",
    "\n",
    "# Create graph from edge list\n",
    "G = nx.from_pandas_edgelist(df,\n",
    "                            source='Source',\n",
    "                            target='Target',\n",
    "                            edge_attr=['Weight', 'Season'])\n",
    "\n",
    "print(f\"Game of Thrones Network:\")\n",
    "print(f\"  Nodes (characters): {len(G.nodes())}\")\n",
    "print(f\"  Edges (interactions): {len(G.edges())}\")\n",
    "print(f\"  Graph density: {nx.density(G):.4f}\")\n",
    "print(f\"  Average clustering: {nx.average_clustering(G):.4f}\")\n",
    "print(f\"\\n  Sample nodes: {list(G.nodes())[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6d7fe",
   "metadata": {},
   "source": [
    "### Apply Louvain algorithm to detect communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = nx.community.louvain_communities(G, resolution=1.5, seed=42)\n",
    "# Construct a mapping node -> community_id\n",
    "node_to_comm = {\n",
    "    node: comm_id\n",
    "    for comm_id, community in enumerate(partition)\n",
    "    for node in community\n",
    "}\n",
    "\n",
    "# Print community statistics\n",
    "print_community_stats(G, partition, name=\"Louvain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb9a364",
   "metadata": {},
   "source": [
    "### Visualizing Louvain Communities\n",
    "\n",
    "Let's visualize the Game of Thrones network with nodes colored by their detected communities:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593eee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_graph_with_communities(\n",
    "    G, \n",
    "    partition, \n",
    "    title=\"Game of Thrones Character Communities (Louvain Algorithm)\",\n",
    "    figsize=(14, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe43ff68-4a56-46fa-845b-0030f4504e51",
   "metadata": {},
   "source": [
    "#### On Facebook followers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38ce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load friends.graphml\n",
    "G = nx.read_graphml(\"../../data/followers.graphml\")\n",
    "G = G.to_undirected()\n",
    "\n",
    "# print the number of nodes and edges\n",
    "print(f\"Number of nodes: {len(G.nodes())}\")\n",
    "print(f\"Number of edges: {len(G.edges())}\")\n",
    "\n",
    "# apply louvain algorithm\n",
    "partition = nx.community.louvain_communities(G, resolution=3, seed=42)\n",
    "\n",
    "len(partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4a031-d779-442f-b9a6-180ec0567df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display name of the characters in the communities\n",
    "for comm_id, community in enumerate(partition):\n",
    "    if len(community) > 5:\n",
    "        print(\"-----------------------\")\n",
    "        print(f\"Community {comm_id}: {', '.join([G.nodes[node]['name'] for node in community])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58de47c9-7d75-499a-b6f8-1a5f97353a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the communities\n",
    "plot_graph_with_communities(\n",
    "    G, \n",
    "    partition, \n",
    "    title=\"Friends Character Communities (Louvain Algorithm)\",\n",
    "    figsize=(14, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36192f34",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part II: Node Embedding-Based Community Detection\n",
    "\n",
    "In this section, we'll use **node embeddings** to represent nodes as vectors in a high-dimensional space, then apply traditional clustering algorithms to detect communities.\n",
    "\n",
    "## 2.1 Node2Vec Embedding\n",
    "\n",
    "**Node2Vec** is a powerful algorithm that learns continuous feature representations for nodes in networks. It:\n",
    "- Uses random walks to explore the network structure\n",
    "- Applies the Skip-gram model (similar to Word2Vec) to learn embeddings\n",
    "- Captures both local and global network properties\n",
    "- Produces embeddings that preserve network neighborhoods\n",
    "\n",
    "### Key Parameters:\n",
    "- `dimensions`: Size of the embedding vector (typically 64-128)\n",
    "- `walk_length`: Length of random walks\n",
    "- `num_walks`: Number of walks per node\n",
    "- `p`, `q`: Control the random walk behavior (BFS vs DFS exploration)\n",
    "\n",
    "**Reference**: [Node2Vec GitHub](https://github.com/eliorc/node2vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f41c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Create Node2Vec model\n",
    "# dimensions=64 creates 64-dimensional vectors for each node\n",
    "# workers=4 uses 4 parallel workers for faster computation\n",
    "# seed=42 for reproducibility\n",
    "node2vec = Node2Vec(G, dimensions=256, walk_length=30, num_walks=200, \n",
    "                    workers=4, seed=42, p=1, q=1)\n",
    "\n",
    "print(\"Node2Vec model initialized!\")\n",
    "print(f\"  Graph: {len(G.nodes())} nodes, {len(G.edges())} edges\")\n",
    "print(f\"  Embedding dimensions: 64\")\n",
    "print(f\"  Walk length: 30\")\n",
    "print(f\"  Number of walks per node: 200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02991a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train the Node2Vec model\n",
    "# This generates random walks and trains the embedding model\n",
    "model = node2vec.fit()\n",
    "\n",
    "print(\"Model trained successfully!\")\n",
    "print(f\"  Vocabulary size: {len(model.wv.key_to_index)}\")\n",
    "print(f\"  Vector dimensions: {model.wv.vectors.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2761d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the embedding vectors as a DataFrame\n",
    "embeddings_df = pd.DataFrame(\n",
    "    model.wv.vectors,\n",
    "    index=model.wv.index_to_key\n",
    ")\n",
    "print(f\"Embedding matrix shape: {embeddings_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "embeddings_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1746ea",
   "metadata": {},
   "source": [
    "## 2.2 Exploring Node Similarities\n",
    "\n",
    "One of the powerful features of node embeddings is that we can find nodes that are \"similar\" in the network structure, even if they're not directly connected. This is done by computing cosine similarity between embedding vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ff0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find characters most similar to DROGO based on network structure\n",
    "target_character = 'DROGO'\n",
    "similar_nodes = model.wv.most_similar(target_character, topn=10)\n",
    "\n",
    "print(f\"Characters most similar to {target_character} (based on network embedding):\\n\")\n",
    "for i, (character, similarity) in enumerate(similar_nodes, 1):\n",
    "    print(f\"{i:2d}. {character:15s} (similarity: {similarity:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918e530-3d52-4a23-8f8d-cedf889b5df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Check if these characters are in the same community\n",
    "print(f\"\\nCommunity analysis:\")\n",
    "drogo_community = node_to_comm.get(target_character, -1)\n",
    "print(f\"{target_character} belongs to community {drogo_community}\")\n",
    "print(f\"\\nSimilar characters' communities:\")\n",
    "for character, similarity in similar_nodes[:10]:\n",
    "    char_community = node_to_comm.get(character, -1)\n",
    "    same_comm = \"‚úì\" if char_community == drogo_community else \"‚úó\"\n",
    "    print(f\"  {character:15s} -> Community {char_community} {same_comm}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4f8a65",
   "metadata": {},
   "source": [
    "## 2.3 Dimension Reduction with t-SNE\n",
    "\n",
    "While Node2Vec creates 256-dimensional vectors, we need to reduce this to 2D for visualization. **t-SNE** (t-distributed Stochastic Neighbor Embedding) is perfect for this:\n",
    "- Preserves local neighborhoods (similar nodes stay close)\n",
    "- Reveals clusters and community structure\n",
    "- Creates beautiful 2D visualizations\n",
    "\n",
    "**Reference**: [openTSNE documentation](https://github.com/pavlin-policar/openTSNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Apply t-SNE to reduce 256D embeddings to 2D\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_embedded = tsne.fit(model.wv.vectors)\n",
    "\n",
    "print(f\"Dimension reduction complete!\")\n",
    "print(f\"  Original dimensions: {model.wv.vectors.shape} (64D)\")\n",
    "print(f\"  Reduced dimensions: {X_embedded.shape} (2D)\")\n",
    "print(f\"  Reduction ratio: {model.wv.vectors.shape[1] / X_embedded.shape[1]}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b23199",
   "metadata": {},
   "source": [
    "## 2.4 Visualizing Embedded Nodes\n",
    "\n",
    "Now let's create an interactive visualization of the 2D embeddings, colored by the communities we found using the Louvain algorithm. This will help us see if the embedding-based representation aligns with the graph-based communities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f243f9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with embeddings and community information\n",
    "df_emb = pd.DataFrame(X_embedded, columns=['x', 'y'])\n",
    "df_emb['name'] = model.wv.index_to_key\n",
    "df_emb['louvain_community'] = df_emb['name'].apply(lambda name: node_to_comm.get(name, -1))\n",
    "df_emb['community_label'] = df_emb['louvain_community'].apply(\n",
    "    lambda x: f'Community {x}' if x != -1 else 'Unknown'\n",
    ")\n",
    "# Display the dataframe\n",
    "print(\"Embedding DataFrame with community labels:\")\n",
    "df_emb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc71d66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive scatter plot with Plotly\n",
    "fig = px.scatter(\n",
    "    df_emb, \n",
    "    x='x', \n",
    "    y='y', \n",
    "    hover_name='name',\n",
    "    color='community_label',\n",
    "    color_discrete_sequence=px.colors.qualitative.Set3,\n",
    "    title='Node Embeddings in 2D Space (colored by Louvain communities)',\n",
    "    labels={'x': 't-SNE Dimension 1', 'y': 't-SNE Dimension 2'},\n",
    "    height=800,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "# Improve the layout\n",
    "fig.update_traces(marker=dict(size=8, opacity=0.7, line=dict(width=0.5, color='DarkSlateGrey')))\n",
    "fig.update_layout(\n",
    "    title_font_size=16,\n",
    "    hovermode='closest',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8595ed",
   "metadata": {},
   "source": [
    "### üéØ Insights from the Visualization\n",
    "\n",
    "- **Clustered nodes**: Nodes that are close in 2D space are similar in network structure\n",
    "- **Community separation**: If Louvain communities form distinct clusters in the embedding space, it suggests the communities are well-defined\n",
    "- **Outliers**: Nodes far from their community clusters might be bridges or have ambiguous community membership\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186ac79",
   "metadata": {},
   "source": [
    "## 2.5 Clustering on Embeddings\n",
    "\n",
    "Now let's apply traditional clustering algorithms directly on the node embeddings to detect communities. We'll compare three different algorithms:\n",
    "\n",
    "1. **K-Means**: Partition-based clustering, requires specifying the number of clusters\n",
    "2. **DBSCAN**: Density-based clustering, finds clusters of varying shapes\n",
    "3. **OPTICS**: Ordering points to identify clustering structure, similar to DBSCAN but handles varying densities\n",
    "\n",
    "### Choosing the Right Embedding Space:\n",
    "- **64D embeddings**: More accurate, captures full structural information\n",
    "- **2D embeddings**: Less accurate but visualization matches the clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose embedding space for clustering\n",
    "# Option 1: Use 2D embeddings (matches visualization but less precise)\n",
    "X = df_emb[['x', 'y']].values\n",
    "\n",
    "# Option 2: Use 256D embeddings (more accurate but visualization won't match)\n",
    "#X = model.wv.vectors\n",
    "\n",
    "print(f\"Using {'2D' if X.shape[1] == 2 else '64D'} embeddings for clustering\")\n",
    "print(f\"Shape: {X.shape}\")\n",
    "\n",
    "# Define clustering algorithms\n",
    "clusterings = [\n",
    "    ('K-Means', KMeans(n_clusters=len(set(node_to_comm.values())), random_state=42, n_init=10)),\n",
    "    ('DBSCAN', DBSCAN(min_samples=3, eps=2.0)),\n",
    "    ('OPTICS', OPTICS(min_samples=3, metric='euclidean'))\n",
    "]\n",
    "\n",
    "# Store results\n",
    "clustering_results = {}\n",
    "\n",
    "for name, clustering_alg in clusterings:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Applying {name}...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Fit the clustering algorithm\n",
    "    labels = clustering_alg.fit_predict(X)\n",
    "    \n",
    "    # Calculate number of clusters (excluding noise points labeled as -1)\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    \n",
    "    print(f\"  Number of clusters: {n_clusters}\")\n",
    "    if n_noise > 0:\n",
    "        print(f\"  Noise points: {n_noise}\")\n",
    "    \n",
    "    # Calculate silhouette score (only if more than 1 cluster)\n",
    "    if n_clusters > 1 and n_noise == 0:\n",
    "        try:\n",
    "            silhouette = silhouette_score(X, labels)\n",
    "            print(f\"  Silhouette score: {silhouette:.4f}\")\n",
    "        except:\n",
    "            print(f\"  Silhouette score: Cannot compute (noise points present)\")\n",
    "    \n",
    "    # Store results\n",
    "    clustering_results[name] = labels\n",
    "    \n",
    "    # Create visualization\n",
    "    df_emb[f'{name}_cluster'] = labels\n",
    "    df_emb[f'{name}_label'] = df_emb[f'{name}_cluster'].apply(\n",
    "        lambda x: f'Cluster {x}' if x != -1 else 'Noise'\n",
    "    )\n",
    "    \n",
    "    # Create plot\n",
    "    fig = px.scatter(\n",
    "        df_emb, \n",
    "        x='x', \n",
    "        y='y', \n",
    "        hover_name='name',\n",
    "        color=f'{name}_label',\n",
    "        title=f'{name} Clustering Results (on {\"2D\" if X.shape[1] == 2 else \"64D\"} embeddings)',\n",
    "        labels={'x': 't-SNE Dimension 1', 'y': 't-SNE Dimension 2'},\n",
    "        height=800,\n",
    "        width=1200\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(marker=dict(size=8, opacity=0.7))\n",
    "    fig.update_layout(title_font_size=16, hovermode='closest')\n",
    "    fig.show()\n",
    "    \n",
    "    # Print cluster sizes\n",
    "    cluster_sizes = pd.Series(labels).value_counts().sort_index()\n",
    "    print(f\"\\n  Cluster sizes:\")\n",
    "    for cluster_id, size in cluster_sizes.items():\n",
    "        if cluster_id == -1:\n",
    "            print(f\"    Noise: {size} nodes\")\n",
    "        else:\n",
    "            print(f\"    Cluster {cluster_id}: {size} nodes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010d33ac",
   "metadata": {},
   "source": [
    "### Graph-Based Methods (Louvain, Girvan-Newman):\n",
    "- ‚úÖ **Pros**: \n",
    "  - Work directly on graph structure\n",
    "  - Optimize modularity (quality measure)\n",
    "  - Fast and scalable (Louvain)\n",
    "  - No need for embeddings\n",
    "  \n",
    "- ‚ùå **Cons**:\n",
    "  - Limited to graph structure only\n",
    "  - May miss latent similarities\n",
    "  - Hard to incorporate node features\n",
    "\n",
    "### Embedding-Based Methods (Node2Vec + Clustering):\n",
    "- ‚úÖ **Pros**:\n",
    "  - Can capture complex relationships\n",
    "  - Flexible (works with any clustering algorithm)\n",
    "  - Can incorporate node features\n",
    "  - Enables similarity search\n",
    "  \n",
    "- ‚ùå **Cons**:\n",
    "  - Requires additional step (embedding)\n",
    "  - More parameters to tune\n",
    "  - Clustering quality depends on embedding quality\n",
    "  - May not optimize graph-specific metrics (modularity)\n",
    "\n",
    "### When to Use What?\n",
    "- **Louvain**: Default choice for most community detection tasks\n",
    "- **Node2Vec + Clustering**: When you need node embeddings for other tasks, or want to incorporate additional features\n",
    "- **Girvan-Newman**: When you need hierarchical community structure\n",
    "- **DBSCAN/OPTICS**: When you expect communities of varying densities or want to identify outliers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
